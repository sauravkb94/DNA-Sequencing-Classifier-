{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNI5rlqE1HC4doU2+aeoZkg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sauravkb94/DNA-Sequencing-Classifier-/blob/main/DNA_Sequencing_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtf155giksGF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "human_data = pd.read_table('/content/human.txt')"
      ],
      "metadata": {
        "id": "0LKcXATzpR89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_data"
      ],
      "metadata": {
        "id": "Ad7RNXJauKut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import plotly.express as ex\n",
        "import plotly.graph_objs as go\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.offline as pyo"
      ],
      "metadata": {
        "id": "lCgWJ_b2v5fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "YExpZpD7Ib0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "geneFamily = cv2.imread(\"/content/genefamily.PNG\")\n",
        "plt.imshow(geneFamily)"
      ],
      "metadata": {
        "id": "NEEL00l0Jll8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = human_data['class'].value_counts()\n",
        "plt.figure(figsize= (8,4))\n",
        "sns.barplot(count.index, count.values)\n",
        "plt.title(\"Human Class \",fontsize=10)\n",
        "plt.xlabel('No of Occurances')\n",
        "plt.ylabel('Category');\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "molLew2mu-57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex.pie(human_data,names='class',title='Propotion Of Human Classes',hole=0.5)"
      ],
      "metadata": {
        "id": "5eoF0MBMvuYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_data['length'] = human_data['sequence'].apply(len)"
      ],
      "metadata": {
        "id": "KhRvebGjxGbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_data.hist(column= 'length', by = 'class', bins = 20, figsize=(12,12) );"
      ],
      "metadata": {
        "id": "hwmTOdA3x0qH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's define a function to collect all possible overlapping n-grams of a specified length from any sequence string. We will basically apply the n-grams to the complete sequences.**"
      ],
      "metadata": {
        "id": "dQxkse4HqKpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "allData=[human_data]"
      ],
      "metadata": {
        "id": "C0baNb1rLBCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getKmers(gene, size=4):\n",
        "    allKmers=\"\"\n",
        "    for i in range(len(gene) - size + 1):\n",
        "        allKmers+=gene[i:i+size]\n",
        "        allKmers+=\" \"\n",
        "    return allKmers[:-1]"
      ],
      "metadata": {
        "id": "E5sUoTAoK5Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert sequence strings into n-grams words, default size = 6 (hexamer words)\n",
        "def create_ngrams(sequence, size=6):\n",
        "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]"
      ],
      "metadata": {
        "id": "-tu_qsuApx6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_data['n-grams'] = human_data['sequence'].apply(create_ngrams)\n"
      ],
      "metadata": {
        "id": "gnh_an9h2Lxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_data.head(10)"
      ],
      "metadata": {
        "id": "qbUW6t-B2hKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Since we are going to use scikit-learn natural language processing tools to do the k-mer counting, we need to now convert the lists of k-mers for each gene into string sentences of words that the count vectorizer can use. We can also make a y variable to hold the class labels. Let's do that now.**"
      ],
      "metadata": {
        "id": "whKYOCAPqo5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "human_text = list(human_data['n-grams'])"
      ],
      "metadata": {
        "id": "dXa_SX9BqrZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in range(len(human_text)):\n",
        "   human_text[item] = ' '.join(human_text[item])"
      ],
      "metadata": {
        "id": "lmAWItB_3qTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_text[1]"
      ],
      "metadata": {
        "id": "RFYCbgYW4rsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_data['human_text'] = human_text"
      ],
      "metadata": {
        "id": "gIi1uQWH5GQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_data.head(5)"
      ],
      "metadata": {
        "id": "Hefn94eP5Slz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(allData)):\n",
        "    allData[i][\"human_text\"]=allData[i]['sequence'].apply(lambda x: getKmers(x))\n",
        "    allData[i].drop(columns='sequence',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "LC8YKR5WMen-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "allData[0]"
      ],
      "metadata": {
        "id": "Xcn0wxy7MtQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now we will apply the BAG of WORDS using CountVectorizer using NLP**"
      ],
      "metadata": {
        "id": "HY4fe5gArWef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "for i in range(len(allData)):\n",
        "    cv = TfidfVectorizer(ngram_range=(5,5))\n",
        "    X=allData[i]['human_text']\n",
        "    Y=allData[i]['class']\n",
        "    X = cv.fit_transform(X)\n",
        "    allData[i]=[X,Y]"
      ],
      "metadata": {
        "id": "bAOVaomhNDZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM\n",
        "from sklearn import metrics \n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "QsJ81wkdNisb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "ACCURACY_THRESHOLD = 0.95\n",
        "class endRun(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if(logs.get('accuracy') > ACCURACY_THRESHOLD):   \n",
        "            self.model.stop_training = True\n",
        "callbacks = endRun()"
      ],
      "metadata": {
        "id": "oKrXO_wJNoQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match=[0,0,0]\n",
        "mismatch=[0,0,0]\n",
        "for i in range(len(allData)):\n",
        "    X=allData[i][0]\n",
        "    y=allData[i][1]\n",
        "    _,input_sp=X.shape\n",
        "    x=X.toarray()\n",
        "    y=pd.get_dummies(y).values\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size = .75)\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64,input_shape = (input_sp,), activation = 'relu'))\n",
        "    model.add(Dense(32, activation = 'relu'))\n",
        "    model.add(Dense(16, activation = 'relu'))\n",
        "    model.add(Dense(32, activation = 'relu'))\n",
        "    model.add(Dense(64, activation = 'relu'))\n",
        "    model.add(Dense(16, activation = 'relu'))\n",
        "    model.add(Dense(7,activation='softmax'))\n",
        "    print(model.summary())\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy',metrics=['accuracy',])\n",
        "    his = model.fit(X_train, y_train, epochs=5000, batch_size=128,verbose=1,callbacks=[callbacks])\n",
        "    yPred=model.predict(X_test)\n",
        "    for j in range(len(yPred)):\n",
        "        ans=yPred[j].tolist()\n",
        "        pred=ans.index(max(ans))\n",
        "        actual=np.where(y_test[j]==1)[0].tolist()[0]\n",
        "        if(pred==actual):\n",
        "            match[i]+=1\n",
        "            continue\n",
        "        mismatch[i]+=1"
      ],
      "metadata": {
        "id": "R26Y3C2wOPPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataof=[\"human\"]\n",
        "for i in range(1):\n",
        "    accuracy=match[i]/(match[i]+mismatch[i])\n",
        "    print(dataof[i],accuracy)"
      ],
      "metadata": {
        "id": "7f-rP66iOzjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = his.history\n",
        "h.keys()"
      ],
      "metadata": {
        "id": "65luqO9tKHAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(h['loss'], c= \"red\")\n",
        "plt.plot(h['accuracy'], c = \"blue\",)\n",
        "\n",
        "plt.title(\"loss vs accuracy\")\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "eIvTV9juLmBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import classification_report,accuracy_score"
      ],
      "metadata": {
        "id": "6cpA8ZAGOPMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = 'Random Forest Classfier'\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "rf_predicted = rf.predict(X_test)\n",
        "rf_acc_score = accuracy_score(y_test, rf_predicted) "
      ],
      "metadata": {
        "id": "4jD5fx-zOPI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\")\n",
        "print(\"Accuracy of Random Forest:\",rf_acc_score,'\\n')\n",
        "print(classification_report(y_test,rf_predicted))"
      ],
      "metadata": {
        "id": "xmr2Ir86OPGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtc= DecisionTreeClassifier()\n",
        "dtc.fit(X_train,y_train)\n",
        "y_pred_dtc = dtc.predict(X_test)"
      ],
      "metadata": {
        "id": "G1YLfzCMOPDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtc_acc_score = accuracy_score(y_test, y_pred_dtc)"
      ],
      "metadata": {
        "id": "jQJfAm7hOPAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\")\n",
        "print(\"Accuracy of Decision Tree :\",dtc_acc_score,'\\n')\n",
        "print(classification_report(y_test,rf_predicted))"
      ],
      "metadata": {
        "id": "eut_4KueOO9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the weight of Words model using TfidfTransformer()\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_data = TfidfTransformer().fit_transform(X)"
      ],
      "metadata": {
        "id": "4mNQSbuhNIZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Multinomial Naive Bayes Classifier ###\n",
        "# The alpha parameter was determined by grid search previously\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "metadata": {
        "id": "4cY5TDdCSDCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = MultinomialNB(alpha=0.1)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "46Kxr-D0SC-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SZIU4rjqSCyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mjpf8CXNSCu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "stTlWfT2SCrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z5Uqo0diSCoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CmElnVNzSCkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QjvTG0sgSChb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jEZdFXOzSCd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bQ9nq11aSCas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Bag of Words model using CountVectorizer()\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(ngram_range=(4,4))\n",
        "for i in range(len(allData)):\n",
        "    cv = TfidfVectorizer(ngram_range=(5,5))\n",
        "    X=allData[i]['human_text']\n",
        "    Y=allData[i]['class']\n",
        "    X = cv.fit_transform(X)\n",
        "    allData[i]=[X,Y]\n",
        "\n",
        "\n",
        "X = vectorizer.fit_transform(df['human_text'])"
      ],
      "metadata": {
        "id": "2kXyoYP9rY0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "ZFiVHTSuriEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "9OPiN-D3-6js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the weight of Words model using TfidfTransformer()\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_data = TfidfTransformer().fit_transform(X)"
      ],
      "metadata": {
        "id": "f8pD5Fop-Ifk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_data.shape"
      ],
      "metadata": {
        "id": "H4V5WdNs9Jk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the human dataset into the training set and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_data, \n",
        "                                                df['class'], \n",
        "                                                    test_size = 0.20, \n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "Ul8EGo5TrvtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "AEbY3Af_rxjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "qX76nBzAArWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Creation"
      ],
      "metadata": {
        "id": "LiGK0ftcmpTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A multinomial naive Bayes classifier will be created. .**"
      ],
      "metadata": {
        "id": "pEd2Iwihr0S3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Multinomial Naive Bayes Classifier ###\n",
        "# The alpha parameter was determined by grid search previously\n",
        "from sklearn.naive_bayes import MultinomialNB\n"
      ],
      "metadata": {
        "id": "_HPzPEKCr2On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = MultinomialNB(alpha=0.1)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "LQphQM1Sr_WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "6g-TlOiYsDF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Model performce metrics like the confusion matrix, accuracy, precision, recall and f1 score**"
      ],
      "metadata": {
        "id": "zIOvPDO5sQkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "print(\"Confusion matrix\\n\")\n",
        "print(pd.crosstab(pd.Series(y_test, name='Actual'), pd.Series(y_pred, name='Predicted')))\n"
      ],
      "metadata": {
        "id": "hrrXiUCOsTEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(y_test, y_predicted):\n",
        "    accuracy = accuracy_score(y_test, y_predicted)\n",
        "    precision = precision_score(y_test, y_predicted, average='weighted')\n",
        "    recall = recall_score(y_test, y_predicted, average='weighted')\n",
        "    f1 = f1_score(y_test, y_predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred)\n",
        "print(\"accuracy = %.3f \\nprecision = %.3f \\nrecall = %.3f \\nf1 = %.3f\" % (accuracy, precision, recall, f1))"
      ],
      "metadata": {
        "id": "09nUYKqgCu0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import classification_report,accuracy_score"
      ],
      "metadata": {
        "id": "5vEOnFeEHREP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = 'Random Forest Classfier'\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "rf_predicted = rf.predict(X_test)\n",
        "rf_acc_score = accuracy_score(y_test, rf_predicted)   "
      ],
      "metadata": {
        "id": "Gk3sB9bOCCV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\")\n",
        "print(\"Accuracy of Random Forest:\",rf_acc_score,'\\n')\n",
        "print(classification_report(y_test,rf_predicted))"
      ],
      "metadata": {
        "id": "TaDUs1CJDjeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtc= DecisionTreeClassifier()\n",
        "dtc.fit(X_train,y_train)\n",
        "y_pred_dtc = dtc.predict(X_test)"
      ],
      "metadata": {
        "id": "1a83Ja6tG87C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtc_acc_score = accuracy_score(y_test, y_pred_dtc)"
      ],
      "metadata": {
        "id": "KmEZKG3BHSZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\")\n",
        "print(\"Accuracy of Decision Tree :\",dtc_acc_score,'\\n')\n",
        "print(classification_report(y_test,rf_predicted))"
      ],
      "metadata": {
        "id": "0VmGJeXoHU-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm"
      ],
      "metadata": {
        "id": "Hz1xRNHCxNMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_clf = svm.SVC(kernel='rbf', C=1, random_state=0)\n",
        "svm_clf.fit(X_train, y_train)\n",
        "predicted = svm_clf.predict(X_test)\n",
        "score = svm_clf.score(y_test, y_pred)\n",
        "svm_score_ = np.mean(score)\n",
        "\n",
        "print('Accuracy : %.3f' % (svm_score_))"
      ],
      "metadata": {
        "id": "wlCXImYdxUPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ev = pd.DataFrame({'Model': ['Confusion matrix Classifier','Decision Tree Classifier','Random Forest Classfier'],'Accuracy': [\" %.3f\" % (accuracy),dtc_acc_score,rf_acc_score]})\n",
        "model_ev"
      ],
      "metadata": {
        "id": "HquzMydfOFuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jxjJrSL-TW31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W4gHgnZbOXzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FV4I8f6gTWYf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}