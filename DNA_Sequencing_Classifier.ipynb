{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyMUxFziC+ijn7NVgGRtLOU7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sauravkb94/DNA-Sequencing-Classifier-/blob/main/DNA_Sequencing_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtf155giksGF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_table('/content/human.txt')"
      ],
      "metadata": {
        "id": "0LKcXATzpR89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Ad7RNXJauKut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = df['class'].value_counts()\n",
        "plt.figure(figsize= (8,4))\n",
        "sns.barplot(count.index, count.values)\n",
        "plt.xlabel('No of Occurances')\n",
        "plt.ylabel('Category');"
      ],
      "metadata": {
        "id": "molLew2mu-57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['length'] = df['sequence'].apply(len)"
      ],
      "metadata": {
        "id": "KhRvebGjxGbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist(column= 'length', by = 'class', bins = 20, figsize=(12,12) );"
      ],
      "metadata": {
        "id": "hwmTOdA3x0qH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's define a function to collect all possible overlapping n-grams of a specified length from any sequence string. We will basically apply the n-grams to the complete sequences.**"
      ],
      "metadata": {
        "id": "dQxkse4HqKpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert sequence strings into n-grams words, default size = 6 (hexamer words)\n",
        "def create_ngrams(sequence, size=6):\n",
        "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]"
      ],
      "metadata": {
        "id": "-tu_qsuApx6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['n-grams'] = df['sequence'].apply(create_ngrams)"
      ],
      "metadata": {
        "id": "gnh_an9h2Lxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "qbUW6t-B2hKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Since we are going to use scikit-learn natural language processing tools to do the k-mer counting, we need to now convert the lists of k-mers for each gene into string sentences of words that the count vectorizer can use. We can also make a y variable to hold the class labels. Let's do that now.**"
      ],
      "metadata": {
        "id": "whKYOCAPqo5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "human_text = list(df['n-grams'])"
      ],
      "metadata": {
        "id": "dXa_SX9BqrZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in range(len(human_text)):\n",
        "   human_text[item] = ' '.join(human_text[item])"
      ],
      "metadata": {
        "id": "lmAWItB_3qTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_text[1]"
      ],
      "metadata": {
        "id": "RFYCbgYW4rsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['human_text'] = human_text"
      ],
      "metadata": {
        "id": "gIi1uQWH5GQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "Hefn94eP5Slz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now we will apply the BAG of WORDS using CountVectorizer using NLP**"
      ],
      "metadata": {
        "id": "HY4fe5gArWef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Bag of Words model using CountVectorizer()\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(ngram_range=(4,4))\n",
        "X = vectorizer.fit_transform(df['human_text'])"
      ],
      "metadata": {
        "id": "2kXyoYP9rY0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "ZFiVHTSuriEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "9OPiN-D3-6js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the weight of Words model using TfidfTransformer()\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_data = TfidfTransformer().fit_transform(X)"
      ],
      "metadata": {
        "id": "f8pD5Fop-Ifk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_data.shape"
      ],
      "metadata": {
        "id": "H4V5WdNs9Jk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the human dataset into the training set and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_data, \n",
        "                                                df['class'], \n",
        "                                                    test_size = 0.20, \n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "Ul8EGo5TrvtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "AEbY3Af_rxjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "qX76nBzAArWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A multinomial naive Bayes classifier will be created. .**"
      ],
      "metadata": {
        "id": "pEd2Iwihr0S3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Multinomial Naive Bayes Classifier ###\n",
        "# The alpha parameter was determined by grid search previously\n",
        "from sklearn.naive_bayes import MultinomialNB\n"
      ],
      "metadata": {
        "id": "_HPzPEKCr2On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = MultinomialNB(alpha=0.1)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "LQphQM1Sr_WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "6g-TlOiYsDF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Model performce metrics like the confusion matrix, accuracy, precision, recall and f1 score**"
      ],
      "metadata": {
        "id": "zIOvPDO5sQkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "print(\"Confusion matrix\\n\")\n",
        "print(pd.crosstab(pd.Series(y_test, name='Actual'), pd.Series(y_pred, name='Predicted')))\n"
      ],
      "metadata": {
        "id": "hrrXiUCOsTEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_metrics(y_test, y_predicted):\n",
        "    accuracy = accuracy_score(y_test, y_predicted)\n",
        "    precision = precision_score(y_test, y_predicted, average='weighted')\n",
        "    recall = recall_score(y_test, y_predicted, average='weighted')\n",
        "    f1 = f1_score(y_test, y_predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred)\n",
        "print(\"accuracy = %.3f \\nprecision = %.3f \\nrecall = %.3f \\nf1 = %.3f\" % (accuracy, precision, recall, f1))"
      ],
      "metadata": {
        "id": "09nUYKqgCu0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import classification_report,accuracy_score"
      ],
      "metadata": {
        "id": "5vEOnFeEHREP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = 'Random Forest Classfier'\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "rf_predicted = rf.predict(X_test)\n",
        "rf_acc_score = accuracy_score(y_test, rf_predicted)   "
      ],
      "metadata": {
        "id": "Gk3sB9bOCCV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\")\n",
        "print(\"Accuracy of Random Forest:\",rf_acc_score,'\\n')\n",
        "print(classification_report(y_test,rf_predicted))"
      ],
      "metadata": {
        "id": "TaDUs1CJDjeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtc= DecisionTreeClassifier()\n",
        "dtc.fit(X_train,y_train)\n",
        "y_pred_dtc = dtc.predict(X_test)"
      ],
      "metadata": {
        "id": "1a83Ja6tG87C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtc_acc_score = accuracy_score(y_test, y_pred_dtc)"
      ],
      "metadata": {
        "id": "KmEZKG3BHSZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\")\n",
        "print(\"Accuracy of Decision Tree :\",dtc_acc_score,'\\n')\n",
        "print(classification_report(y_test,rf_predicted))"
      ],
      "metadata": {
        "id": "0VmGJeXoHU-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ev = pd.DataFrame({'Model': ['Confusion matrix Classifier','Decision Tree Classifier','Random Forest Classfier'],'Accuracy': [\" %.3f\" % (accuracy),dtc_acc_score,rf_acc_score]})\n",
        "model_ev"
      ],
      "metadata": {
        "id": "HquzMydfOFuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jxjJrSL-TW31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W4gHgnZbOXzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FV4I8f6gTWYf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}