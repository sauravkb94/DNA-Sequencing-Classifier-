{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOr/sSTbC5EcwJTBdo9QefK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sauravkb94/DNA-Sequencing-Classifier-/blob/main/DNA_Sequencing_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtf155giksGF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install biopython"
      ],
      "metadata": {
        "id": "Z9DEficorhM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Bio"
      ],
      "metadata": {
        "id": "GpZfRrXOro5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "for sequence in SeqIO.parse('/content/example_dna.fa', \"fasta\"):\n",
        "    print(sequence.id)\n",
        "    print(sequence.seq)\n",
        "    print(len(sequence))"
      ],
      "metadata": {
        "id": "AavEE9rdrPbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One-hot encoding DNA Sequence**"
      ],
      "metadata": {
        "id": "AOHmDTO5r0Ss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Another approach is to use one-hot encoding to represent the DNA sequence. This is widely used in deep learning methods and lends itself well to algorithms like convolutional neural networks. In this example, “ATGC” would become [0,0,0,1], [0,0,1,0], [0,1,0,0], [1,0,0,0]. And these one-hot encoded vectors can either be concatenated or turned into 2-dimensional arrays."
      ],
      "metadata": {
        "id": "p44YwW0Wry31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "def string_to_array(seq_string):\n",
        "   seq_string = seq_string.lower()\n",
        "   seq_string = re.sub('[^acgt]', 'n', seq_string)\n",
        "   seq_string = np.array(list(seq_string))\n",
        "   return seq_string\n",
        "# create a label encoder with 'acgtn' alphabet\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(np.array(['a','c','g','t','z']))"
      ],
      "metadata": {
        "id": "iIwz-2qtsDEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "def one_hot_encoder(seq_string):\n",
        "    int_encoded = label_encoder.transform(seq_string)\n",
        "    onehot_encoder = OneHotEncoder(sparse=False, dtype=int)\n",
        "    int_encoded = int_encoded.reshape(len(int_encoded), 1)\n",
        "    onehot_encoded = onehot_encoder.fit_transform(int_encoded)\n",
        "    onehot_encoded = np.delete(onehot_encoded, -1, 1)\n",
        "    return onehot_encoded"
      ],
      "metadata": {
        "id": "1C3QDFI-ryH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#So let’s try it out with a simple short sequence:\n",
        "seq_test = 'GAATTCTCGAA'\n",
        "one_hot_encoder(string_to_array(seq_test))"
      ],
      "metadata": {
        "id": "grSxRFInr73s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ],
      "metadata": {
        "id": "xlOZq2--sV11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_data = pd.read_table('/content/human.txt')"
      ],
      "metadata": {
        "id": "0LKcXATzpR89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_data"
      ],
      "metadata": {
        "id": "Ad7RNXJauKut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import plotly.express as ex\n",
        "import plotly.graph_objs as go\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.offline as pyo"
      ],
      "metadata": {
        "id": "lCgWJ_b2v5fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "YExpZpD7Ib0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "geneFamily = cv2.imread(\"/content/genefamily.PNG\")\n",
        "plt.imshow(geneFamily)"
      ],
      "metadata": {
        "id": "NEEL00l0Jll8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = human_data['class'].value_counts()\n",
        "plt.figure(figsize= (8,4))\n",
        "sns.barplot(x=count.index, y=count.values, alpha=0.8)\n",
        "plt.title(\"Human Class \",fontsize=10)\n",
        "plt.xlabel('No of Occurances')\n",
        "plt.ylabel('Category');\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "molLew2mu-57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex.pie(human_data,names='class',title='Propotion Of Human Classes',hole=0.5)"
      ],
      "metadata": {
        "id": "5eoF0MBMvuYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_data['length'] = human_data['sequence'].apply(len)"
      ],
      "metadata": {
        "id": "KhRvebGjxGbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_data.hist(column= 'length', by = 'class', bins = 20, figsize=(12,12) );"
      ],
      "metadata": {
        "id": "hwmTOdA3x0qH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's define a function to collect all possible overlapping n-grams of a specified length from any sequence string. We will basically apply the n-grams to the complete sequences.**"
      ],
      "metadata": {
        "id": "dQxkse4HqKpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "allData=[human_data]"
      ],
      "metadata": {
        "id": "C0baNb1rLBCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getKmers(gene, size=4):\n",
        "    allKmers=\"\"\n",
        "    for i in range(len(gene) - size + 1):\n",
        "        allKmers+=gene[i:i+size]\n",
        "        allKmers+=\" \"\n",
        "    return allKmers[:-1]"
      ],
      "metadata": {
        "id": "E5sUoTAoK5Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert sequence strings into n-grams words, default size = 6 (hexamer words)\n",
        "def create_ngrams(sequence, size=6):\n",
        "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]"
      ],
      "metadata": {
        "id": "-tu_qsuApx6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_data['n-grams'] = human_data['sequence'].apply(create_ngrams)\n"
      ],
      "metadata": {
        "id": "gnh_an9h2Lxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_data.head(10)"
      ],
      "metadata": {
        "id": "qbUW6t-B2hKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Since we are going to use scikit-learn natural language processing tools to do the k-mer counting, we need to now convert the lists of k-mers for each gene into string sentences of words that the count vectorizer can use. We can also make a y variable to hold the class labels. Let's do that now.**"
      ],
      "metadata": {
        "id": "whKYOCAPqo5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "human_text = list(human_data['n-grams'])"
      ],
      "metadata": {
        "id": "dXa_SX9BqrZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in range(len(human_text)):\n",
        "   human_text[item] = ' '.join(human_text[item])"
      ],
      "metadata": {
        "id": "lmAWItB_3qTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_text[1]"
      ],
      "metadata": {
        "id": "RFYCbgYW4rsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_data['human_text'] = human_text"
      ],
      "metadata": {
        "id": "gIi1uQWH5GQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_data.head(5)"
      ],
      "metadata": {
        "id": "Hefn94eP5Slz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(allData)):\n",
        "    allData[i][\"human_text\"]=allData[i]['sequence'].apply(lambda x: getKmers(x))\n",
        "    allData[i].drop(columns='sequence',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "LC8YKR5WMen-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "allData[0]"
      ],
      "metadata": {
        "id": "Xcn0wxy7MtQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now we will apply the BAG of WORDS using CountVectorizer using NLP**"
      ],
      "metadata": {
        "id": "HY4fe5gArWef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "for i in range(len(allData)):\n",
        "    cv = TfidfVectorizer(ngram_range=(5,5))\n",
        "    X=allData[i]['human_text']\n",
        "    Y=allData[i]['class']\n",
        "    X = cv.fit_transform(X)\n",
        "    allData[i]=[X,Y]"
      ],
      "metadata": {
        "id": "bAOVaomhNDZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM\n",
        "from sklearn import metrics \n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "QsJ81wkdNisb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "ACCURACY_THRESHOLD = 0.95\n",
        "class endRun(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if(logs.get('accuracy') > ACCURACY_THRESHOLD):   \n",
        "            self.model.stop_training = True\n",
        "callbacks = endRun()"
      ],
      "metadata": {
        "id": "oKrXO_wJNoQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match=[0,0,0]\n",
        "mismatch=[0,0,0]\n",
        "for i in range(len(allData)):\n",
        "    X=allData[i][0]\n",
        "    y=allData[i][1]\n",
        "    _,input_sp=X.shape\n",
        "    x=X.toarray()\n",
        "    y=pd.get_dummies(y).values\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size = .75)\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64,input_shape = (input_sp,), activation = 'relu'))\n",
        "    model.add(Dense(32, activation = 'relu'))\n",
        "    model.add(Dense(16, activation = 'relu'))\n",
        "    model.add(Dense(32, activation = 'relu'))\n",
        "    model.add(Dense(64, activation = 'relu'))\n",
        "    model.add(Dense(16, activation = 'relu'))\n",
        "    model.add(Dense(7,activation='softmax'))\n",
        "    print(model.summary())\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy',metrics=['accuracy',])\n",
        "    his = model.fit(X_train, y_train, epochs=5000, batch_size=128,verbose=1,callbacks=[callbacks])\n",
        "    yPred=model.predict(X_test)\n",
        "    for j in range(len(yPred)):\n",
        "        ans=yPred[j].tolist()\n",
        "        pred=ans.index(max(ans))\n",
        "        actual=np.where(y_test[j]==1)[0].tolist()[0]\n",
        "        if(pred==actual):\n",
        "            match[i]+=1\n",
        "            continue\n",
        "        mismatch[i]+=1"
      ],
      "metadata": {
        "id": "R26Y3C2wOPPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataof=[\"human\"]\n",
        "for i in range(1):\n",
        "    accuracy=match[i]/(match[i]+mismatch[i])\n",
        "    print(dataof[i],accuracy*100)"
      ],
      "metadata": {
        "id": "7f-rP66iOzjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = his.history\n",
        "h.keys()"
      ],
      "metadata": {
        "id": "65luqO9tKHAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(h['loss'], c= \"red\")\n",
        "plt.plot(h['accuracy'], c = \"blue\",)\n",
        "\n",
        "plt.title(\"loss vs accuracy\")\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "eIvTV9juLmBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import classification_report,accuracy_score"
      ],
      "metadata": {
        "id": "6cpA8ZAGOPMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = 'Random Forest Classfier'\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "rf_predicted = rf.predict(X_test)\n",
        "rf_acc_score = accuracy_score(y_test, rf_predicted) "
      ],
      "metadata": {
        "id": "4jD5fx-zOPI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\")\n",
        "print(\"Accuracy of Random Forest:\",rf_acc_score,'\\n')\n",
        "print(classification_report(y_test,rf_predicted))"
      ],
      "metadata": {
        "id": "xmr2Ir86OPGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtc= DecisionTreeClassifier()\n",
        "dtc.fit(X_train,y_train)\n",
        "y_pred_dtc = dtc.predict(X_test)"
      ],
      "metadata": {
        "id": "G1YLfzCMOPDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtc_acc_score = accuracy_score(y_test, y_pred_dtc)"
      ],
      "metadata": {
        "id": "jQJfAm7hOPAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\")\n",
        "print(\"Accuracy of Decision Tree :\",dtc_acc_score,'\\n')\n",
        "print(classification_report(y_test,rf_predicted))"
      ],
      "metadata": {
        "id": "eut_4KueOO9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn= KNeighborsClassifier()\n",
        "knn.fit(X_train,y_train)\n",
        "y_pred_knn = knn.predict(X_test)"
      ],
      "metadata": {
        "id": "3DsgCZSioFi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_acc_score = accuracy_score(y_test, y_pred_knn)"
      ],
      "metadata": {
        "id": "9YP2Ae6roO8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\")\n",
        "print(\"Accuracy of Kneighbors :\",knn_acc_score,'\\n')\n",
        "print(classification_report(y_test,rf_predicted))"
      ],
      "metadata": {
        "id": "DCKmC00IoZz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ev = pd.DataFrame({'Model': ['Random Forest Classfier','Decision Tree Classifier','K Neighbors Classifier'],'Accuracy': [rf_acc_score*100,dtc_acc_score*100,knn_acc_score*100]})\n",
        "model_ev"
      ],
      "metadata": {
        "id": "HquzMydfOFuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jxjJrSL-TW31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W4gHgnZbOXzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FV4I8f6gTWYf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}